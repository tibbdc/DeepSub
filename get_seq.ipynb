{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sys,os\n",
    "from tool.att import Attention\n",
    "from keras.models import load_model\n",
    "import esm\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import logging\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "data = pd.read_csv(\"./DATA/complexPortal_num(1).tsv\",sep='\\t')\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fasta_data(ids):\n",
    "    data_list = []\n",
    "    \n",
    "    for ID in ids:\n",
    "        url = f\"https://rest.uniprot.org/uniprotkb/{ID}.fasta\"\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            fasta_data = response.text\n",
    "        else:\n",
    "            fasta_data = f\"Failed to download data for ID {ID}. Status code: {response.status_code}\"\n",
    "        \n",
    "        header, *sequence_lines = fasta_data.split('\\n')\n",
    "        uniprot_id = header.split('|')[1]\n",
    "        sequence = ''.join(sequence_lines)\n",
    "        \n",
    "        data_list.append({'uniprot_id': uniprot_id, 'seq': sequence})\n",
    "    \n",
    "    dataset = pd.DataFrame(data_list)\n",
    "    return dataset\n",
    "\n",
    "# Example usage:\n",
    "ID_list = [\"A0A2A9IR05\", \"P12345\", \"Q9Y617\"]\n",
    "result_dataset = get_fasta_data(ID_list)\n",
    "result_dataset.to_csv(\"output/download_seq.csv\",index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linjw/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esm2 embedding\n",
    "def get_rep_seq(sequences):\n",
    "\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(sequences)\n",
    "    batch_tokens = batch_tokens.to(device)\n",
    "    batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens, repr_layers=[33], return_contacts=False)\n",
    "    token_representations = results[\"representations\"][33]\n",
    "    sequence_representations = []\n",
    "    for i, tokens_len in enumerate(batch_lens):\n",
    "        sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
    "       \n",
    "    np_list = []\n",
    "\n",
    "    for i, ten in enumerate(sequence_representations):\n",
    "        ten=ten.cpu().detach().numpy()\n",
    "        np_list.append(ten)\n",
    "    res = pd.DataFrame(np_list)\n",
    "    res.columns = ['f'+str(i) for i in range (0,res.shape[1])]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.26s/it]\n"
     ]
    }
   ],
   "source": [
    "df_data = list(zip(dataset.uniprot_id.index,dataset.seq))\n",
    "\n",
    "# Run in batches\n",
    "stride =2\n",
    "num_iterations = len(df_data) // stride\n",
    "if len(df_data) % stride != 0:\n",
    "    num_iterations += 1\n",
    "    \n",
    "# Embedding\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(num_iterations)):\n",
    "    \n",
    "    start = i * stride\n",
    "    end = start + stride\n",
    "\n",
    "    current_data = df_data[start:end]\n",
    "\n",
    "    rep33 = get_rep_seq(sequences=current_data)\n",
    "    rep33['uniprot_id'] = dataset[start:end].uniprot_id.tolist()\n",
    "    cols = list(rep33.columns)\n",
    "    cols = [cols[-1]] + cols[:-1]\n",
    "    rep33 = rep33[cols]\n",
    "    all_results = pd.concat([all_results, rep33], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 08:08:26.655808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15770 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:73:00.0, compute capability: 8.6\n",
      "2024-03-04 08:08:27.490935: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-04 08:08:29.511625: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "These are the predicted labels:\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "# Deepsub\n",
    "model = load_model(\"./model/deepsub_new.h5\",custom_objects={\"Attention\": Attention},compile=False)\n",
    "predicted = model.predict(np.array(all_results.iloc[:,1:]).reshape(all_results.shape[0],1,-1))\n",
    "predicted_labels = np.argmax(predicted, axis=1)\n",
    "label_map = {0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 10, 9: 12}\n",
    "y_test_transformed = [label_map[x] for x in predicted_labels]\n",
    "print(\"These are the predicted labels:\")\n",
    "print(y_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x7f21db1109d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1, 1280)]         0         \n",
      "                                                                 \n",
      " bi-gru (Bidirectional)      (None, 1, 256)            1082880   \n",
      "                                                                 \n",
      " attention (Attention)       (None, 256)               8225      \n",
      "                                                                 \n",
      " attention_dropout (Dropout  (None, 256)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1093675 (4.17 MB)\n",
      "Trainable params: 1093675 (4.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
