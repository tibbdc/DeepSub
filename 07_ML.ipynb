{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 08:32:08.583976: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-22 08:32:08.584025: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-22 08:32:08.584060: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-22 08:32:08.594448: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-22 08:32:10.453126: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from trainer import load_and_preprocess_data\n",
    "from tool import utils as ul\n",
    "from tool import config as cfg\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 1 ...\n",
      "X_train: (86691, 1280)\n",
      "X_val: (9633, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [0 1 1 ... 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linjw/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 1 1 1]\n",
      "Training for fold 2 ...\n",
      "X_train: (86691, 1280)\n",
      "X_val: (9633, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linjw/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 1 1 1]\n",
      "Training for fold 3 ...\n",
      "X_train: (86691, 1280)\n",
      "X_val: (9633, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [0 1 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [0 3 1 ... 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linjw/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****DeepSub*****\n",
      "predicted_classes: [0 1 1 ... 1 1 1]\n",
      "Training for fold 4 ...\n",
      "X_train: (86691, 1280)\n",
      "X_val: (9633, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 0 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linjw/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 0 1 1]\n",
      "Training for fold 5 ...\n",
      "X_train: (86692, 1280)\n",
      "X_val: (9632, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 1 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 1 1 ... 1 5 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linjw/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****DeepSub*****\n",
      "predicted_classes: [9 1 1 ... 1 0 1]\n",
      "Training for fold 6 ...\n",
      "X_train: (86692, 1280)\n",
      "X_val: (9632, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 0 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 0 1 ... 1 1 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linjw/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****DeepSub*****\n",
      "predicted_classes: [9 1 1 ... 1 1 2]\n",
      "Training for fold 7 ...\n",
      "X_train: (86692, 1280)\n",
      "X_val: (9632, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 9 9 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 9 9 ... 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linjw/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****DeepSub*****\n",
      "predicted_classes: [9 9 9 ... 1 1 1]\n",
      "Training for fold 8 ...\n",
      "X_train: (86692, 1280)\n",
      "X_val: (9632, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 1 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 1 1 ... 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linjw/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****DeepSub*****\n",
      "predicted_classes: [9 1 1 ... 1 1 1]\n",
      "Training for fold 9 ...\n",
      "X_train: (86692, 1280)\n",
      "X_val: (9632, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 9 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 9 ... 1 3 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linjw/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 9 ... 1 1 1]\n",
      "Training for fold 10 ...\n",
      "X_train: (86692, 1280)\n",
      "X_val: (9632, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linjw/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****DeepSub*****\n",
      "predicted_classes: [3 0 0 ... 1 1 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947265</td>\n",
       "      <td>0.886866</td>\n",
       "      <td>0.812262</td>\n",
       "      <td>0.846779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959929</td>\n",
       "      <td>0.875584</td>\n",
       "      <td>0.849769</td>\n",
       "      <td>0.862288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902834</td>\n",
       "      <td>0.829166</td>\n",
       "      <td>0.726245</td>\n",
       "      <td>0.771228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>2</td>\n",
       "      <td>0.950898</td>\n",
       "      <td>0.888932</td>\n",
       "      <td>0.800344</td>\n",
       "      <td>0.840113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.958891</td>\n",
       "      <td>0.966984</td>\n",
       "      <td>0.891242</td>\n",
       "      <td>0.920372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lr</td>\n",
       "      <td>2</td>\n",
       "      <td>0.913838</td>\n",
       "      <td>0.831190</td>\n",
       "      <td>0.745318</td>\n",
       "      <td>0.783893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rf</td>\n",
       "      <td>3</td>\n",
       "      <td>0.950690</td>\n",
       "      <td>0.889864</td>\n",
       "      <td>0.805174</td>\n",
       "      <td>0.843823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.958995</td>\n",
       "      <td>0.864903</td>\n",
       "      <td>0.854649</td>\n",
       "      <td>0.859518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lr</td>\n",
       "      <td>3</td>\n",
       "      <td>0.908751</td>\n",
       "      <td>0.820676</td>\n",
       "      <td>0.756850</td>\n",
       "      <td>0.786358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rf</td>\n",
       "      <td>4</td>\n",
       "      <td>0.948510</td>\n",
       "      <td>0.887882</td>\n",
       "      <td>0.792554</td>\n",
       "      <td>0.834642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.959514</td>\n",
       "      <td>0.869492</td>\n",
       "      <td>0.841844</td>\n",
       "      <td>0.855082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lr</td>\n",
       "      <td>4</td>\n",
       "      <td>0.911969</td>\n",
       "      <td>0.839698</td>\n",
       "      <td>0.742244</td>\n",
       "      <td>0.784777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rf</td>\n",
       "      <td>5</td>\n",
       "      <td>0.949128</td>\n",
       "      <td>0.889647</td>\n",
       "      <td>0.799699</td>\n",
       "      <td>0.840549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.956188</td>\n",
       "      <td>0.958420</td>\n",
       "      <td>0.938918</td>\n",
       "      <td>0.948156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lr</td>\n",
       "      <td>5</td>\n",
       "      <td>0.908430</td>\n",
       "      <td>0.825331</td>\n",
       "      <td>0.726393</td>\n",
       "      <td>0.770509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rf</td>\n",
       "      <td>6</td>\n",
       "      <td>0.948609</td>\n",
       "      <td>0.889054</td>\n",
       "      <td>0.812028</td>\n",
       "      <td>0.847223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>knn</td>\n",
       "      <td>6</td>\n",
       "      <td>0.959406</td>\n",
       "      <td>0.965222</td>\n",
       "      <td>0.947946</td>\n",
       "      <td>0.956104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lr</td>\n",
       "      <td>6</td>\n",
       "      <td>0.908223</td>\n",
       "      <td>0.834257</td>\n",
       "      <td>0.745359</td>\n",
       "      <td>0.784894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rf</td>\n",
       "      <td>7</td>\n",
       "      <td>0.951931</td>\n",
       "      <td>0.889406</td>\n",
       "      <td>0.815245</td>\n",
       "      <td>0.849490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>knn</td>\n",
       "      <td>7</td>\n",
       "      <td>0.958264</td>\n",
       "      <td>0.863035</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.854429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lr</td>\n",
       "      <td>7</td>\n",
       "      <td>0.914556</td>\n",
       "      <td>0.838932</td>\n",
       "      <td>0.730923</td>\n",
       "      <td>0.775875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rf</td>\n",
       "      <td>8</td>\n",
       "      <td>0.946013</td>\n",
       "      <td>0.885958</td>\n",
       "      <td>0.804321</td>\n",
       "      <td>0.841000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>knn</td>\n",
       "      <td>8</td>\n",
       "      <td>0.956914</td>\n",
       "      <td>0.867794</td>\n",
       "      <td>0.839786</td>\n",
       "      <td>0.853121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lr</td>\n",
       "      <td>8</td>\n",
       "      <td>0.901370</td>\n",
       "      <td>0.815709</td>\n",
       "      <td>0.742090</td>\n",
       "      <td>0.775569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rf</td>\n",
       "      <td>9</td>\n",
       "      <td>0.950789</td>\n",
       "      <td>0.889532</td>\n",
       "      <td>0.815846</td>\n",
       "      <td>0.849805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>knn</td>\n",
       "      <td>9</td>\n",
       "      <td>0.959510</td>\n",
       "      <td>0.963047</td>\n",
       "      <td>0.950775</td>\n",
       "      <td>0.956746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>lr</td>\n",
       "      <td>9</td>\n",
       "      <td>0.913414</td>\n",
       "      <td>0.833619</td>\n",
       "      <td>0.746455</td>\n",
       "      <td>0.785305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.951620</td>\n",
       "      <td>0.889610</td>\n",
       "      <td>0.815527</td>\n",
       "      <td>0.849518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>knn</td>\n",
       "      <td>10</td>\n",
       "      <td>0.957018</td>\n",
       "      <td>0.858443</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.854590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lr</td>\n",
       "      <td>10</td>\n",
       "      <td>0.912272</td>\n",
       "      <td>0.817705</td>\n",
       "      <td>0.740447</td>\n",
       "      <td>0.774669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Fold  Accuracy  Precision    Recall  F1 Score\n",
       "0     rf     1  0.947265   0.886866  0.812262  0.846779\n",
       "1    knn     1  0.959929   0.875584  0.849769  0.862288\n",
       "2     lr     1  0.902834   0.829166  0.726245  0.771228\n",
       "3     rf     2  0.950898   0.888932  0.800344  0.840113\n",
       "4    knn     2  0.958891   0.966984  0.891242  0.920372\n",
       "5     lr     2  0.913838   0.831190  0.745318  0.783893\n",
       "6     rf     3  0.950690   0.889864  0.805174  0.843823\n",
       "7    knn     3  0.958995   0.864903  0.854649  0.859518\n",
       "8     lr     3  0.908751   0.820676  0.756850  0.786358\n",
       "9     rf     4  0.948510   0.887882  0.792554  0.834642\n",
       "10   knn     4  0.959514   0.869492  0.841844  0.855082\n",
       "11    lr     4  0.911969   0.839698  0.742244  0.784777\n",
       "12    rf     5  0.949128   0.889647  0.799699  0.840549\n",
       "13   knn     5  0.956188   0.958420  0.938918  0.948156\n",
       "14    lr     5  0.908430   0.825331  0.726393  0.770509\n",
       "15    rf     6  0.948609   0.889054  0.812028  0.847223\n",
       "16   knn     6  0.959406   0.965222  0.947946  0.956104\n",
       "17    lr     6  0.908223   0.834257  0.745359  0.784894\n",
       "18    rf     7  0.951931   0.889406  0.815245  0.849490\n",
       "19   knn     7  0.958264   0.863035  0.846939  0.854429\n",
       "20    lr     7  0.914556   0.838932  0.730923  0.775875\n",
       "21    rf     8  0.946013   0.885958  0.804321  0.841000\n",
       "22   knn     8  0.956914   0.867794  0.839786  0.853121\n",
       "23    lr     8  0.901370   0.815709  0.742090  0.775569\n",
       "24    rf     9  0.950789   0.889532  0.815846  0.849805\n",
       "25   knn     9  0.959510   0.963047  0.950775  0.956746\n",
       "26    lr     9  0.913414   0.833619  0.746455  0.785305\n",
       "27    rf    10  0.951620   0.889610  0.815527  0.849518\n",
       "28   knn    10  0.957018   0.858443  0.851064  0.854590\n",
       "29    lr    10  0.912272   0.817705  0.740447  0.774669"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_and_preprocess_data()\n",
    "X = np.array(dataset.iloc[:, 3:])\n",
    "y = dataset['label'].values\n",
    "\n",
    "# Define the K-fold cross-validator\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "fold_no = 1\n",
    "\n",
    "models_results = {'knn','lr','rf'}\n",
    "\n",
    "fold_metrics = {\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1 Score': [],\n",
    "    }\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Model', 'Fold', 'Accuracy', 'Precision', 'Recall', 'F1_Score'])\n",
    "res = []\n",
    "\n",
    "for train, test in kfold.split(X, y):\n",
    "\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Split data into training and validation sets\n",
    "    X_train, X_val = X[train], X[test]\n",
    "    y_train, y_val = y[train], y[test]\n",
    "    \n",
    "    print(f'X_train: {X_train.shape}')\n",
    "    print(f'X_val: {X_val.shape}')\n",
    "    \n",
    "    for model_name in models_results:\n",
    "        \n",
    "        predicted_classes = ul.run_baseline(X_train, y_train, X_val, y_val, type='multi',method=model_name)\n",
    "        \n",
    "        # Save metrics\n",
    "        print(f'predicted_classes: {predicted_classes}')\n",
    "        accuracy  = accuracy_score(y_val, predicted_classes)\n",
    "        precision = precision_score(y_val, predicted_classes, average='macro', zero_division=0)\n",
    "        recall    = recall_score(y_val, predicted_classes, average='macro', zero_division=0)\n",
    "        f1        = f1_score(y_val, predicted_classes, average='macro', zero_division=0)\n",
    "\n",
    "        # Save metrics to dataframe\n",
    "        res.append({\n",
    "            'Model': model_name,\n",
    "            'Fold': fold_no,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1\n",
    "        })\n",
    "    \n",
    "    # Increment fold number\n",
    "    fold_no += 1  \n",
    "    \n",
    "results_df = pd.DataFrame(res)\n",
    "results_df.to_csv('output/cross_validation_results_ml.csv', index=False)\n",
    "display(results_df)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biobase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
