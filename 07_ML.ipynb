{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 11:23:51.614661: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-22 11:23:51.614716: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-22 11:23:51.614748: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-22 11:23:51.626245: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-22 11:23:53.688181: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from trainer import load_and_preprocess_data\n",
    "from tool import utils as ul\n",
    "from tool import config as cfg\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****DeepSub*****\n",
      "*****DeepSub*****\n",
      "*****DeepSub*****\n",
      "*****DeepSub*****\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.982259</td>\n",
       "      <td>0.893875</td>\n",
       "      <td>0.935985</td>\n",
       "      <td>4212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.915926</td>\n",
       "      <td>0.994681</td>\n",
       "      <td>0.953681</td>\n",
       "      <td>10153.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.995627</td>\n",
       "      <td>0.870064</td>\n",
       "      <td>0.928620</td>\n",
       "      <td>785.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997080</td>\n",
       "      <td>0.892810</td>\n",
       "      <td>0.942069</td>\n",
       "      <td>2295.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.879433</td>\n",
       "      <td>0.935849</td>\n",
       "      <td>141.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934534</td>\n",
       "      <td>0.966159</td>\n",
       "      <td>1222.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.758170</td>\n",
       "      <td>0.862454</td>\n",
       "      <td>153.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.927374</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.947885</td>\n",
       "      <td>0.947885</td>\n",
       "      <td>0.947885</td>\n",
       "      <td>0.947885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.889089</td>\n",
       "      <td>0.806376</td>\n",
       "      <td>0.843984</td>\n",
       "      <td>19265.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.951131</td>\n",
       "      <td>0.947885</td>\n",
       "      <td>0.947426</td>\n",
       "      <td>19265.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "0              0.982259  0.893875  0.935985   4212.000000\n",
       "1              0.915926  0.994681  0.953681  10153.000000\n",
       "2              0.995627  0.870064  0.928620    785.000000\n",
       "3              0.997080  0.892810  0.942069   2295.000000\n",
       "4              1.000000  0.879433  0.935849    141.000000\n",
       "5              1.000000  0.934534  0.966159   1222.000000\n",
       "6              0.000000  0.000000  0.000000      3.000000\n",
       "7              1.000000  0.758170  0.862454    153.000000\n",
       "8              1.000000  0.975610  0.987654    205.000000\n",
       "9              1.000000  0.864583  0.927374     96.000000\n",
       "accuracy       0.947885  0.947885  0.947885      0.947885\n",
       "macro avg      0.889089  0.806376  0.843984  19265.000000\n",
       "weighted avg   0.951131  0.947885  0.947426  19265.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.860897</td>\n",
       "      <td>0.847816</td>\n",
       "      <td>0.854306</td>\n",
       "      <td>4212.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.915702</td>\n",
       "      <td>0.911553</td>\n",
       "      <td>0.913623</td>\n",
       "      <td>10153.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.833972</td>\n",
       "      <td>0.831847</td>\n",
       "      <td>0.832908</td>\n",
       "      <td>785.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.837388</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.846054</td>\n",
       "      <td>2295.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>141.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.868982</td>\n",
       "      <td>0.900982</td>\n",
       "      <td>0.884693</td>\n",
       "      <td>1222.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.628049</td>\n",
       "      <td>0.673203</td>\n",
       "      <td>0.649842</td>\n",
       "      <td>153.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.873171</td>\n",
       "      <td>0.846336</td>\n",
       "      <td>205.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.721649</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.725389</td>\n",
       "      <td>96.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.733557</td>\n",
       "      <td>0.745243</td>\n",
       "      <td>0.739186</td>\n",
       "      <td>19265.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.883199</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.883041</td>\n",
       "      <td>19265.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score    support\n",
       "0              0.860897  0.847816  0.854306   4212.000\n",
       "1              0.915702  0.911553  0.913623  10153.000\n",
       "2              0.833972  0.831847  0.832908    785.000\n",
       "3              0.837388  0.854902  0.846054   2295.000\n",
       "4              0.847826  0.829787  0.838710    141.000\n",
       "5              0.868982  0.900982  0.884693   1222.000\n",
       "6              0.000000  0.000000  0.000000      3.000\n",
       "7              0.628049  0.673203  0.649842    153.000\n",
       "8              0.821101  0.873171  0.846336    205.000\n",
       "9              0.721649  0.729167  0.725389     96.000\n",
       "accuracy       0.883000  0.883000  0.883000      0.883\n",
       "macro avg      0.733557  0.745243  0.739186  19265.000\n",
       "weighted avg   0.883199  0.883000  0.883041  19265.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.945516</td>\n",
       "      <td>0.931149</td>\n",
       "      <td>0.938278</td>\n",
       "      <td>4212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.959374</td>\n",
       "      <td>0.972225</td>\n",
       "      <td>0.965757</td>\n",
       "      <td>10153.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.962567</td>\n",
       "      <td>0.917197</td>\n",
       "      <td>0.939335</td>\n",
       "      <td>785.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.954165</td>\n",
       "      <td>0.943355</td>\n",
       "      <td>0.948729</td>\n",
       "      <td>2295.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.948148</td>\n",
       "      <td>0.907801</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>141.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.960033</td>\n",
       "      <td>0.963175</td>\n",
       "      <td>0.961601</td>\n",
       "      <td>1222.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.931973</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>153.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.990244</td>\n",
       "      <td>0.971292</td>\n",
       "      <td>205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.955671</td>\n",
       "      <td>0.955671</td>\n",
       "      <td>0.955671</td>\n",
       "      <td>0.955671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.959235</td>\n",
       "      <td>0.876016</td>\n",
       "      <td>0.900640</td>\n",
       "      <td>19265.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.955625</td>\n",
       "      <td>0.955671</td>\n",
       "      <td>0.955545</td>\n",
       "      <td>19265.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "0              0.945516  0.931149  0.938278   4212.000000\n",
       "1              0.959374  0.972225  0.965757  10153.000000\n",
       "2              0.962567  0.917197  0.939335    785.000000\n",
       "3              0.954165  0.943355  0.948729   2295.000000\n",
       "4              0.948148  0.907801  0.927536    141.000000\n",
       "5              0.960033  0.963175  0.961601   1222.000000\n",
       "6              1.000000  0.333333  0.500000      3.000000\n",
       "7              0.931973  0.895425  0.913333    153.000000\n",
       "8              0.953052  0.990244  0.971292    205.000000\n",
       "9              0.977528  0.906250  0.940541     96.000000\n",
       "accuracy       0.955671  0.955671  0.955671      0.955671\n",
       "macro avg      0.959235  0.876016  0.900640  19265.000000\n",
       "weighted avg   0.955625  0.955671  0.955545  19265.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.957390</td>\n",
       "      <td>0.933523</td>\n",
       "      <td>0.945306</td>\n",
       "      <td>4212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.949995</td>\n",
       "      <td>0.984241</td>\n",
       "      <td>0.966815</td>\n",
       "      <td>10153.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.984993</td>\n",
       "      <td>0.919745</td>\n",
       "      <td>0.951252</td>\n",
       "      <td>785.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.980813</td>\n",
       "      <td>0.935512</td>\n",
       "      <td>0.957627</td>\n",
       "      <td>2295.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.992063</td>\n",
       "      <td>0.886525</td>\n",
       "      <td>0.936330</td>\n",
       "      <td>141.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.996593</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.976628</td>\n",
       "      <td>1222.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849673</td>\n",
       "      <td>0.918728</td>\n",
       "      <td>153.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980488</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.960602</td>\n",
       "      <td>0.960602</td>\n",
       "      <td>0.960602</td>\n",
       "      <td>0.960602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.886185</td>\n",
       "      <td>0.834299</td>\n",
       "      <td>0.858789</td>\n",
       "      <td>19265.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.961003</td>\n",
       "      <td>0.960602</td>\n",
       "      <td>0.960390</td>\n",
       "      <td>19265.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "0              0.957390  0.933523  0.945306   4212.000000\n",
       "1              0.949995  0.984241  0.966815  10153.000000\n",
       "2              0.984993  0.919745  0.951252    785.000000\n",
       "3              0.980813  0.935512  0.957627   2295.000000\n",
       "4              0.992063  0.886525  0.936330    141.000000\n",
       "5              0.996593  0.957447  0.976628   1222.000000\n",
       "6              0.000000  0.000000  0.000000      3.000000\n",
       "7              1.000000  0.849673  0.918728    153.000000\n",
       "8              1.000000  0.980488  0.990148    205.000000\n",
       "9              1.000000  0.895833  0.945055     96.000000\n",
       "accuracy       0.960602  0.960602  0.960602      0.960602\n",
       "macro avg      0.886185  0.834299  0.858789  19265.000000\n",
       "weighted avg   0.961003  0.960602  0.960390  19265.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_and_preprocess_data()\n",
    "X = np.array(dataset.iloc[:, 3:])\n",
    "y = dataset['label'].values\n",
    "# Load and preprocess the dataset.\n",
    "dataset = load_and_preprocess_data()\n",
    "ground_truth_labels=[]\n",
    "predicted_labels = []\n",
    "\n",
    "train_data, vali_data = train_test_split(dataset, test_size=cfg.TRAIN_TEST_SPLIT_SIZE, stratify=dataset['label'], random_state=42)\n",
    "X_train, y_train = train_data.iloc[:,3:].values, train_data[\"label\"].values\n",
    "X_val, y_val = vali_data.iloc[:,3:].values, vali_data[\"label\"].values\n",
    "models_results = {'knn','dt','rf','xg'}\n",
    "for model_name in models_results:\n",
    "    predicted_classes = ul.run_baseline(X_train, y_train, X_val, y_val, type='multi',method=model_name)\n",
    "    ground_truth_labels.append(y_val)   \n",
    "    predicted_labels.append(predicted_classes)\n",
    "for i in range(len(models_results)):\n",
    "    report = pd.DataFrame(classification_report(ground_truth_labels[i], predicted_labels[i],output_dict=True)).T\n",
    "    display(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {'model': models_results, 'ground_truth': ground_truth_labels, 'predicted': predicted_labels}\n",
    "# Convert the dictionary to a Pandas DataFrame\n",
    "results_df = pd.DataFrame([results_dict])\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('output/ml_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 1 ...\n",
      "X_train: (86691, 1280)\n",
      "X_val: (9633, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [5 0 0 ... 1 1 0]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [0 1 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [3 1 1 ... 1 1 1]\n",
      "Training for fold 2 ...\n",
      "X_train: (86691, 1280)\n",
      "X_val: (9633, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 1 1 1]\n",
      "Training for fold 3 ...\n",
      "X_train: (86691, 1280)\n",
      "X_val: (9633, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [0 1 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 0 1 ... 1 8 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [0 3 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [0 1 1 ... 1 1 1]\n",
      "Training for fold 4 ...\n",
      "X_train: (86691, 1280)\n",
      "X_val: (9633, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 0 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 0 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 0 1 1]\n",
      "Training for fold 5 ...\n",
      "X_train: (86692, 1280)\n",
      "X_val: (9632, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 1 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 1 1 ... 1 5 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 1 1 ... 1 5 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 1 1 ... 1 5 1]\n",
      "Training for fold 6 ...\n",
      "X_train: (86692, 1280)\n",
      "X_val: (9632, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 0 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 0 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 0 1 ... 1 1 6]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 0 1 ... 1 1 1]\n",
      "Training for fold 7 ...\n",
      "X_train: (86692, 1280)\n",
      "X_val: (9632, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 9 9 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 9 9 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 9 9 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 9 9 ... 1 1 1]\n",
      "Training for fold 8 ...\n",
      "X_train: (86692, 1280)\n",
      "X_val: (9632, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 1 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 1 1 ... 5 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 1 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [9 1 1 ... 1 1 1]\n",
      "Training for fold 9 ...\n",
      "X_train: (86692, 1280)\n",
      "X_val: (9632, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 9 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [3 0 9 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 9 ... 1 3 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 9 ... 1 1 1]\n",
      "Training for fold 10 ...\n",
      "X_train: (86692, 1280)\n",
      "X_val: (9632, 1280)\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 1 0 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 1 1 1]\n",
      "*****DeepSub*****\n",
      "predicted_classes: [1 1 1 ... 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947265</td>\n",
       "      <td>0.886866</td>\n",
       "      <td>0.812262</td>\n",
       "      <td>0.846779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dt</td>\n",
       "      <td>1</td>\n",
       "      <td>0.884771</td>\n",
       "      <td>0.747826</td>\n",
       "      <td>0.750748</td>\n",
       "      <td>0.749159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959929</td>\n",
       "      <td>0.875584</td>\n",
       "      <td>0.849769</td>\n",
       "      <td>0.862288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958891</td>\n",
       "      <td>0.886691</td>\n",
       "      <td>0.835250</td>\n",
       "      <td>0.859661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rf</td>\n",
       "      <td>2</td>\n",
       "      <td>0.950898</td>\n",
       "      <td>0.888932</td>\n",
       "      <td>0.800344</td>\n",
       "      <td>0.840113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dt</td>\n",
       "      <td>2</td>\n",
       "      <td>0.890481</td>\n",
       "      <td>0.754831</td>\n",
       "      <td>0.734948</td>\n",
       "      <td>0.742784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>knn</td>\n",
       "      <td>2</td>\n",
       "      <td>0.958891</td>\n",
       "      <td>0.966984</td>\n",
       "      <td>0.891242</td>\n",
       "      <td>0.920372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.960448</td>\n",
       "      <td>0.886341</td>\n",
       "      <td>0.831049</td>\n",
       "      <td>0.857057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rf</td>\n",
       "      <td>3</td>\n",
       "      <td>0.950690</td>\n",
       "      <td>0.889864</td>\n",
       "      <td>0.805174</td>\n",
       "      <td>0.843823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dt</td>\n",
       "      <td>3</td>\n",
       "      <td>0.891000</td>\n",
       "      <td>0.752129</td>\n",
       "      <td>0.761299</td>\n",
       "      <td>0.756241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>knn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.958995</td>\n",
       "      <td>0.864903</td>\n",
       "      <td>0.854649</td>\n",
       "      <td>0.859518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.961590</td>\n",
       "      <td>0.985554</td>\n",
       "      <td>0.891077</td>\n",
       "      <td>0.928964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rf</td>\n",
       "      <td>4</td>\n",
       "      <td>0.948510</td>\n",
       "      <td>0.887882</td>\n",
       "      <td>0.792554</td>\n",
       "      <td>0.834642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dt</td>\n",
       "      <td>4</td>\n",
       "      <td>0.892661</td>\n",
       "      <td>0.750805</td>\n",
       "      <td>0.743160</td>\n",
       "      <td>0.746201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>knn</td>\n",
       "      <td>4</td>\n",
       "      <td>0.959514</td>\n",
       "      <td>0.869492</td>\n",
       "      <td>0.841844</td>\n",
       "      <td>0.855082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.961383</td>\n",
       "      <td>0.881366</td>\n",
       "      <td>0.822822</td>\n",
       "      <td>0.850204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rf</td>\n",
       "      <td>5</td>\n",
       "      <td>0.949128</td>\n",
       "      <td>0.889647</td>\n",
       "      <td>0.799699</td>\n",
       "      <td>0.840549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dt</td>\n",
       "      <td>5</td>\n",
       "      <td>0.886109</td>\n",
       "      <td>0.747602</td>\n",
       "      <td>0.738630</td>\n",
       "      <td>0.743028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>knn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.956188</td>\n",
       "      <td>0.958420</td>\n",
       "      <td>0.938918</td>\n",
       "      <td>0.948156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>xg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.959925</td>\n",
       "      <td>0.882462</td>\n",
       "      <td>0.829041</td>\n",
       "      <td>0.853986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rf</td>\n",
       "      <td>6</td>\n",
       "      <td>0.948609</td>\n",
       "      <td>0.889054</td>\n",
       "      <td>0.812028</td>\n",
       "      <td>0.847223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dt</td>\n",
       "      <td>6</td>\n",
       "      <td>0.886628</td>\n",
       "      <td>0.736871</td>\n",
       "      <td>0.756320</td>\n",
       "      <td>0.746237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>knn</td>\n",
       "      <td>6</td>\n",
       "      <td>0.959406</td>\n",
       "      <td>0.965222</td>\n",
       "      <td>0.947946</td>\n",
       "      <td>0.956104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>xg</td>\n",
       "      <td>6</td>\n",
       "      <td>0.958783</td>\n",
       "      <td>0.884676</td>\n",
       "      <td>0.837618</td>\n",
       "      <td>0.859751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rf</td>\n",
       "      <td>7</td>\n",
       "      <td>0.951931</td>\n",
       "      <td>0.889406</td>\n",
       "      <td>0.815245</td>\n",
       "      <td>0.849490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dt</td>\n",
       "      <td>7</td>\n",
       "      <td>0.888704</td>\n",
       "      <td>0.748091</td>\n",
       "      <td>0.756075</td>\n",
       "      <td>0.751669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>knn</td>\n",
       "      <td>7</td>\n",
       "      <td>0.958264</td>\n",
       "      <td>0.863035</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.854429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>xg</td>\n",
       "      <td>7</td>\n",
       "      <td>0.960029</td>\n",
       "      <td>0.886453</td>\n",
       "      <td>0.834370</td>\n",
       "      <td>0.858989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rf</td>\n",
       "      <td>8</td>\n",
       "      <td>0.946013</td>\n",
       "      <td>0.885958</td>\n",
       "      <td>0.804321</td>\n",
       "      <td>0.841000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>dt</td>\n",
       "      <td>8</td>\n",
       "      <td>0.886524</td>\n",
       "      <td>0.750139</td>\n",
       "      <td>0.748517</td>\n",
       "      <td>0.748821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>knn</td>\n",
       "      <td>8</td>\n",
       "      <td>0.956914</td>\n",
       "      <td>0.867794</td>\n",
       "      <td>0.839786</td>\n",
       "      <td>0.853121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>xg</td>\n",
       "      <td>8</td>\n",
       "      <td>0.956084</td>\n",
       "      <td>0.883420</td>\n",
       "      <td>0.833596</td>\n",
       "      <td>0.857083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>rf</td>\n",
       "      <td>9</td>\n",
       "      <td>0.950789</td>\n",
       "      <td>0.889532</td>\n",
       "      <td>0.815846</td>\n",
       "      <td>0.849805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>dt</td>\n",
       "      <td>9</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.741890</td>\n",
       "      <td>0.750512</td>\n",
       "      <td>0.745906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>knn</td>\n",
       "      <td>9</td>\n",
       "      <td>0.959510</td>\n",
       "      <td>0.963047</td>\n",
       "      <td>0.950775</td>\n",
       "      <td>0.956746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>xg</td>\n",
       "      <td>9</td>\n",
       "      <td>0.962625</td>\n",
       "      <td>0.885107</td>\n",
       "      <td>0.841100</td>\n",
       "      <td>0.862139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>rf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.951620</td>\n",
       "      <td>0.889610</td>\n",
       "      <td>0.815527</td>\n",
       "      <td>0.849518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>dt</td>\n",
       "      <td>10</td>\n",
       "      <td>0.885694</td>\n",
       "      <td>0.754450</td>\n",
       "      <td>0.754149</td>\n",
       "      <td>0.753966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>knn</td>\n",
       "      <td>10</td>\n",
       "      <td>0.957018</td>\n",
       "      <td>0.858443</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.854590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>xg</td>\n",
       "      <td>10</td>\n",
       "      <td>0.962728</td>\n",
       "      <td>0.886165</td>\n",
       "      <td>0.836754</td>\n",
       "      <td>0.859948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Fold  Accuracy  Precision    Recall  F1 Score\n",
       "0     rf     1  0.947265   0.886866  0.812262  0.846779\n",
       "1     dt     1  0.884771   0.747826  0.750748  0.749159\n",
       "2    knn     1  0.959929   0.875584  0.849769  0.862288\n",
       "3     xg     1  0.958891   0.886691  0.835250  0.859661\n",
       "4     rf     2  0.950898   0.888932  0.800344  0.840113\n",
       "5     dt     2  0.890481   0.754831  0.734948  0.742784\n",
       "6    knn     2  0.958891   0.966984  0.891242  0.920372\n",
       "7     xg     2  0.960448   0.886341  0.831049  0.857057\n",
       "8     rf     3  0.950690   0.889864  0.805174  0.843823\n",
       "9     dt     3  0.891000   0.752129  0.761299  0.756241\n",
       "10   knn     3  0.958995   0.864903  0.854649  0.859518\n",
       "11    xg     3  0.961590   0.985554  0.891077  0.928964\n",
       "12    rf     4  0.948510   0.887882  0.792554  0.834642\n",
       "13    dt     4  0.892661   0.750805  0.743160  0.746201\n",
       "14   knn     4  0.959514   0.869492  0.841844  0.855082\n",
       "15    xg     4  0.961383   0.881366  0.822822  0.850204\n",
       "16    rf     5  0.949128   0.889647  0.799699  0.840549\n",
       "17    dt     5  0.886109   0.747602  0.738630  0.743028\n",
       "18   knn     5  0.956188   0.958420  0.938918  0.948156\n",
       "19    xg     5  0.959925   0.882462  0.829041  0.853986\n",
       "20    rf     6  0.948609   0.889054  0.812028  0.847223\n",
       "21    dt     6  0.886628   0.736871  0.756320  0.746237\n",
       "22   knn     6  0.959406   0.965222  0.947946  0.956104\n",
       "23    xg     6  0.958783   0.884676  0.837618  0.859751\n",
       "24    rf     7  0.951931   0.889406  0.815245  0.849490\n",
       "25    dt     7  0.888704   0.748091  0.756075  0.751669\n",
       "26   knn     7  0.958264   0.863035  0.846939  0.854429\n",
       "27    xg     7  0.960029   0.886453  0.834370  0.858989\n",
       "28    rf     8  0.946013   0.885958  0.804321  0.841000\n",
       "29    dt     8  0.886524   0.750139  0.748517  0.748821\n",
       "30   knn     8  0.956914   0.867794  0.839786  0.853121\n",
       "31    xg     8  0.956084   0.883420  0.833596  0.857083\n",
       "32    rf     9  0.950789   0.889532  0.815846  0.849805\n",
       "33    dt     9  0.883721   0.741890  0.750512  0.745906\n",
       "34   knn     9  0.959510   0.963047  0.950775  0.956746\n",
       "35    xg     9  0.962625   0.885107  0.841100  0.862139\n",
       "36    rf    10  0.951620   0.889610  0.815527  0.849518\n",
       "37    dt    10  0.885694   0.754450  0.754149  0.753966\n",
       "38   knn    10  0.957018   0.858443  0.851064  0.854590\n",
       "39    xg    10  0.962728   0.886165  0.836754  0.859948"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_and_preprocess_data()\n",
    "X = np.array(dataset.iloc[:, 3:])\n",
    "y = dataset['label'].values\n",
    "\n",
    "# Define the K-fold cross-validator\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "fold_no = 1\n",
    "\n",
    "fold_metrics = {\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1 Score': [],\n",
    "    }\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Model', 'Fold', 'Accuracy', 'Precision', 'Recall', 'F1_Score'])\n",
    "res = []\n",
    "\n",
    "for train, test in kfold.split(X, y):\n",
    "\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Split data into training and validation sets\n",
    "    X_train, X_val = X[train], X[test]\n",
    "    y_train, y_val = y[train], y[test]\n",
    "    \n",
    "    print(f'X_train: {X_train.shape}')\n",
    "    print(f'X_val: {X_val.shape}')\n",
    "    for model_name in models_results:\n",
    "        \n",
    "        predicted_classes = ul.run_baseline(X_train, y_train, X_val, y_val, type='multi',method=model_name)\n",
    "        \n",
    "        # Save metrics\n",
    "        print(f'predicted_classes: {predicted_classes}')\n",
    "        accuracy  = accuracy_score(y_val, predicted_classes)\n",
    "        precision = precision_score(y_val, predicted_classes, average='macro', zero_division=0)\n",
    "        recall    = recall_score(y_val, predicted_classes, average='macro', zero_division=0)\n",
    "        f1        = f1_score(y_val, predicted_classes, average='macro', zero_division=0)\n",
    "\n",
    "        # Save metrics to dataframe\n",
    "        res.append({\n",
    "            'Model': model_name,\n",
    "            'Fold': fold_no,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1\n",
    "        })\n",
    "    \n",
    "    # Increment fold number\n",
    "    fold_no += 1  \n",
    "    \n",
    "results_df = pd.DataFrame(res)\n",
    "results_df.to_csv('output/cross_validation_results_ml.csv', index=False)\n",
    "display(results_df)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biobase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
