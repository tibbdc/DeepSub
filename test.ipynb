{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sys,os\n",
    "from tool.att import Attention\n",
    "from keras.models import load_model\n",
    "import esm\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import logging\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set gpu\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from fasta \n",
    "url = \"https://rest.uniprot.org/uniprotkb/P08499.fasta\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    fasta_data = response.text\n",
    "else:\n",
    "    fasta_data = \"Failed to download data. Status code: \" + str(response.status_code)\n",
    "    \n",
    "header, *sequence_lines = fasta_data.split('\\n')\n",
    "uniprot_id = header.split('|')[1]\n",
    "sequence = ''.join(sequence_lines)\n",
    "\n",
    "dataset = pd.DataFrame({'uniprot_id': [uniprot_id], 'seq': [sequence]})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esm2 embedding\n",
    "def get_rep_seq(sequences):\n",
    "\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(sequences)\n",
    "    batch_tokens = batch_tokens.to(device)\n",
    "    batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens, repr_layers=[33], return_contacts=False)\n",
    "    token_representations = results[\"representations\"][33]\n",
    "    sequence_representations = []\n",
    "    for i, tokens_len in enumerate(batch_lens):\n",
    "        sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
    "       \n",
    "    np_list = []\n",
    "\n",
    "    for i, ten in enumerate(sequence_representations):\n",
    "        ten=ten.cpu().detach().numpy()\n",
    "        np_list.append(ten)\n",
    "    res = pd.DataFrame(np_list)\n",
    "    res.columns = ['f'+str(i) for i in range (0,res.shape[1])]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.92it/s]\n"
     ]
    }
   ],
   "source": [
    "df_data = list(zip(dataset.uniprot_id.index,dataset.seq))\n",
    "\n",
    "# Run in batches\n",
    "stride =2\n",
    "num_iterations = len(df_data) // stride\n",
    "if len(df_data) % stride != 0:\n",
    "    num_iterations += 1\n",
    "    \n",
    "# Embedding\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(num_iterations)):\n",
    "    \n",
    "    start = i * stride\n",
    "    end = start + stride\n",
    "\n",
    "    current_data = df_data[start:end]\n",
    "\n",
    "    rep33 = get_rep_seq(sequences=current_data)\n",
    "    rep33['uniprot_id'] = dataset[start:end].uniprot_id.tolist()\n",
    "    cols = list(rep33.columns)\n",
    "    cols = [cols[-1]] + cols[:-1]\n",
    "    rep33 = rep33[cols]\n",
    "    all_results = pd.concat([all_results, rep33], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 596ms/step\n",
      "These are the predicted labels:\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "# Deepsub\n",
    "model = load_model(\"./model/deepsub_new.h5\",custom_objects={\"Attention\": Attention},compile=False)\n",
    "predicted = model.predict(np.array(all_results.iloc[:,1:]).reshape(all_results.shape[0],1,-1))\n",
    "predicted_labels = np.argmax(predicted, axis=1)\n",
    "label_map = {0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 10, 9: 12}\n",
    "y_test_transformed = [label_map[x] for x in predicted_labels]\n",
    "print(\"These are the predicted labels:\")\n",
    "print(y_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the predicted labels:\n",
      "[2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linjw/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelBinarizer from version 1.0.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/linjw/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MLPClassifier from version 1.0.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#queen \n",
    "# Load model\n",
    "model_location = \"./model/QUEEN_MLPmodel_final.pkl\"\n",
    "with open(model_location, \"rb\") as f:\n",
    "  QUEEN_model = pickle.load(f)\n",
    "  \n",
    "# Queen pred\n",
    "y_test = QUEEN_model.predict(np.array(all_results.iloc[:,1:]))\n",
    "inv_map = {0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 10, 9: 12, 10: 14, 11: 24}\n",
    "\n",
    "y_test_transformed = np.array([inv_map[x] for x in y_test])\n",
    "print(\"These are the predicted labels:\")\n",
    "print(y_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xg These are the predicted labels:\n",
      "[4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linjw/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn hese are the predicted labels:\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "#knn\n",
    "with open('./model/ml_xg.pkl', 'rb') as file:\n",
    "    xg_model = pickle.load(file)\n",
    "xg_predict = xg_model.predict(all_results.iloc[:,1:])\n",
    "\n",
    "inv_map = {0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 10, 9: 12, 10: 14, 11: 24}\n",
    "\n",
    "y_test_transformed = np.array([inv_map[x] for x in knn_predict])\n",
    "print(\"xg These are the predicted labels:\")\n",
    "print(y_test_transformed)\n",
    "\n",
    "\n",
    "with open('./model/ml_knn.pkl', 'rb') as file:\n",
    "    knn_model = pickle.load(file)\n",
    "xg_predict = xg_model.predict(all_results.iloc[:,1:])\n",
    "knn_predict = knn_model.predict(all_results.iloc[:,1:])\n",
    "\n",
    "inv_map = {0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 10, 9: 12, 10: 14, 11: 24}\n",
    "\n",
    "y_test_transformed = np.array([inv_map[x] for x in knn_predict])\n",
    "print(\"knn hese are the predicted labels:\")\n",
    "print(y_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P08499</td>\n",
       "      <td>MTSASAPSFNPGKGPGSAVGIALLGFGTVGTEVMRLMTEYGDELAH...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uniprot_id                                                seq\n",
       "0     P08499  MTSASAPSFNPGKGPGSAVGIALLGFGTVGTEVMRLMTEYGDELAH..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write finished\n",
      "Write finished\n",
      "diamond makedb --in /tmp/train.fasta -d /tmp/train.dmnd --quiet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "diamond v0.9.30.131 (C) Max Planck Society for the Advancement of Science\n",
      "Documentation, support and updates available at http://www.diamondsearch.org\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diamond blastp -d /tmp/train.dmnd  -q  /tmp/test.fasta -o /tmp/test_fasta_results.tsv -b5 -c1 -k 1 -e 1e-5 --quiet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "diamond v0.9.30.131 (C) Max Planck Society for the Advancement of Science\n",
      "Documentation, support and updates available at http://www.diamondsearch.org\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sseqid</th>\n",
       "      <th>pident</th>\n",
       "      <th>length</th>\n",
       "      <th>mismatch</th>\n",
       "      <th>gapopen</th>\n",
       "      <th>qstart</th>\n",
       "      <th>qend</th>\n",
       "      <th>sstart</th>\n",
       "      <th>send</th>\n",
       "      <th>evalue</th>\n",
       "      <th>bitscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P08499</td>\n",
       "      <td>Q5F8J4</td>\n",
       "      <td>39.9</td>\n",
       "      <td>436</td>\n",
       "      <td>243</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>443</td>\n",
       "      <td>4</td>\n",
       "      <td>431</td>\n",
       "      <td>1.700000e-74</td>\n",
       "      <td>278.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sseqid  pident  length  mismatch  gapopen  qstart  qend  sstart  \\\n",
       "0  P08499  Q5F8J4    39.9     436       243        7      19   443       4   \n",
       "\n",
       "   send        evalue  bitscore  \n",
       "0   431  1.700000e-74     278.9  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#blast\n",
    "from tool import config as cfg\n",
    "from tool.blast import getblast\n",
    "\n",
    "data = pd.read_csv(cfg.DATA_PATH)\n",
    "data = data.rename(columns={'Entry':'id','Sequence':'seq'})\n",
    "dataset = dataset.rename(columns={'uniprot_id':'id'})\n",
    "\n",
    "diamond_task = getblast(train = data, test = dataset)\n",
    "diamond_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>seq</th>\n",
       "      <th>label</th>\n",
       "      <th>organism</th>\n",
       "      <th>EC number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20459</th>\n",
       "      <td>Q5F8J4</td>\n",
       "      <td>MKPVNIGLLGLGTVGGGAAAVLRDNAEEISRRLGREIRISAMCDLS...</td>\n",
       "      <td>4</td>\n",
       "      <td>Neisseria gonorrhoeae (strain ATCC 700825 / FA...</td>\n",
       "      <td>1.1.1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                                seq  label  \\\n",
       "20459  Q5F8J4  MKPVNIGLLGLGTVGGGAAAVLRDNAEEISRRLGREIRISAMCDLS...      4   \n",
       "\n",
       "                                                organism EC number  \n",
       "20459  Neisseria gonorrhoeae (strain ATCC 700825 / FA...   1.1.1.3  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.id=='Q5F8J4']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
