{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 15:36:45.674988: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-23 15:36:45.675059: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-23 15:36:45.675103: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-23 15:36:45.683492: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-23 15:36:47.349365: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sys,os\n",
    "from tool.att import Attention\n",
    "from keras.models import load_model\n",
    "import esm\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import logging\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set gpu\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from fasta \n",
    "url = \"https://rest.uniprot.org/uniprotkb/A0A2A9IR05.fasta\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    fasta_data = response.text\n",
    "else:\n",
    "    fasta_data = \"Failed to download data. Status code: \" + str(response.status_code)\n",
    "    \n",
    "header, *sequence_lines = fasta_data.split('\\n')\n",
    "uniprot_id = header.split('|')[1]\n",
    "sequence = ''.join(sequence_lines)\n",
    "\n",
    "dataset = pd.DataFrame({'uniprot_id': [uniprot_id], 'seq': [sequence]})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esm2 embedding\n",
    "def get_rep_seq(sequences):\n",
    "\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(sequences)\n",
    "    batch_tokens = batch_tokens.to(device)\n",
    "    batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens, repr_layers=[33], return_contacts=False)\n",
    "    token_representations = results[\"representations\"][33]\n",
    "    sequence_representations = []\n",
    "    for i, tokens_len in enumerate(batch_lens):\n",
    "        sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
    "       \n",
    "    np_list = []\n",
    "\n",
    "    for i, ten in enumerate(sequence_representations):\n",
    "        ten=ten.cpu().detach().numpy()\n",
    "        np_list.append(ten)\n",
    "    res = pd.DataFrame(np_list)\n",
    "    res.columns = ['f'+str(i) for i in range (0,res.shape[1])]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "df_data = list(zip(dataset.uniprot_id.index,dataset.seq))\n",
    "\n",
    "# Run in batches\n",
    "stride =2\n",
    "num_iterations = len(df_data) // stride\n",
    "if len(df_data) % stride != 0:\n",
    "    num_iterations += 1\n",
    "    \n",
    "# Embedding\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(num_iterations)):\n",
    "    \n",
    "    start = i * stride\n",
    "    end = start + stride\n",
    "\n",
    "    current_data = df_data[start:end]\n",
    "\n",
    "    rep33 = get_rep_seq(sequences=current_data)\n",
    "    rep33['uniprot_id'] = dataset[start:end].uniprot_id.tolist()\n",
    "    cols = list(rep33.columns)\n",
    "    cols = [cols[-1]] + cols[:-1]\n",
    "    rep33 = rep33[cols]\n",
    "    all_results = pd.concat([all_results, rep33], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 15:37:08.728133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6297 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-02-23 15:37:08.730124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9559 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:25:00.0, compute capability: 8.6\n",
      "2024-02-23 15:37:08.731704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 9559 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2024-02-23 15:37:08.733334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 9559 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:61:00.0, compute capability: 8.6\n",
      "2024-02-23 15:37:08.735015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 9559 MB memory:  -> device: 4, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:81:00.0, compute capability: 8.6\n",
      "2024-02-23 15:37:08.736574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 9559 MB memory:  -> device: 5, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:a1:00.0, compute capability: 8.6\n",
      "2024-02-23 15:37:08.738084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 9559 MB memory:  -> device: 6, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:c1:00.0, compute capability: 8.6\n",
      "2024-02-23 15:37:08.739631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 9559 MB memory:  -> device: 7, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:e1:00.0, compute capability: 8.6\n",
      "2024-02-23 15:37:08.914363: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 673ms/step\n",
      "These are the predicted labels:\n",
      "[4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 15:37:09.929091: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n"
     ]
    }
   ],
   "source": [
    "# Deepsub\n",
    "model = load_model(\"./model/deepsub_new.h5\",custom_objects={\"Attention\": Attention},compile=False)\n",
    "predicted = model.predict(np.array(all_results.iloc[:,1:]).reshape(all_results.shape[0],1,-1))\n",
    "predicted_labels = np.argmax(predicted, axis=1)\n",
    "label_map = {0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 10, 9: 12}\n",
    "y_test_transformed = [label_map[x] for x in predicted_labels]\n",
    "print(\"These are the predicted labels:\")\n",
    "print(y_test_transformed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
